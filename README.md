#  Requirements-to-Tests Generator (T2T)

> **Automatically generate runnable test cases and traceability matrices directly from requirements and API specifications.**

---

##  Overview

Manual test authoring is slow and error-prone â€” every time a requirement changes, QA engineers must rewrite test scripts and update traceability sheets.  
**T2T** automates this entire process.

It reads:

- **Jira change requests** â†’ what the user wants  
- **OpenAPI specifications** â†’ how the API behaves  

and automatically generates:

-  **Gherkin scenarios** (`.feature` files)  
-  **Runnable pytest tests** (`.py` files)  
-  **Traceability matrix** (CSV + HTML)  

This cuts **manual test creation from hours to minutes** while maintaining full traceability from requirement â†’ test â†’ execution result.

---

##  Project Structure

t2t_requirements_to_tests_fixed2/

â”œâ”€â”€ data/

â”‚ â”œâ”€â”€ jira/

â”‚ â”‚ â””â”€â”€ changes.json â† Jira requirements input

â”‚ â””â”€â”€ openapi/

â”‚ â””â”€â”€ my_api.yaml â† OpenAPI specification

â”‚

â”œâ”€â”€ t2t/

â”‚ â”œâ”€â”€ agents/ â† RequirementAgent (core logic)

â”‚ â”œâ”€â”€ generators/ â† Gherkin + pytest file writers

â”‚ â”œâ”€â”€ guardrails/ â† Validation & schema checks

â”‚ â”œâ”€â”€ traceability/ â† Traceability matrix builder

â”‚ â””â”€â”€ utils/ â† Loaders for YAML + JSON

â”‚

â”œâ”€â”€ out/

â”‚ â”œâ”€â”€ features/ â† Generated .feature files

â”‚ â”œâ”€â”€ tests/ â† Generated pytest files

â”‚ â”œâ”€â”€ traceability.csv

â”‚ â””â”€â”€ traceability.html

â”‚
â”œâ”€â”€ .github/workflows/tests.yml â† CI pipeline for GitHub Actions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/AnirudhKandoti/Requirements-to-Tests-Generation.git
cd Requirements-to-Tests-Generation

# Create and activate venv
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux / Mac
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install -e .
pip install pytest
```
Input Files
ğŸ“˜ 1. Jira Requirements â€“ data/jira/changes.json

This file contains simplified Jira export data:
```
[
  {
    "id": "REQ-201",
    "title": "List and view pets",
    "description": "As a user, I can list all pets and fetch one by ID.",
    "links": ["listPets", "GET /pets/{petId}"],
    "priority": "High"
  },
  {
    "id": "REQ-202",
    "title": "Create a new pet",
    "description": "As staff, I can create a new pet entry.",
    "links": ["createPet", "POST /pets"],
    "priority": "Medium"
  }
]
```
You can export these from Jira using its REST API or fill them manually for demo purposes.

2. OpenAPI Specification â€“ data/openapi/my_api.yaml

This defines your API contract (paths, methods, schemas):
```
openapi: 3.0.0
info:
  title: Pets API
  version: 1.0.0
paths:
  /pets:
    get:
      operationId: listPets
      responses:
        '200':
          description: OK
    post:
      operationId: createPet
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                id: { type: string }
                name: { type: string }
      responses:
        '200': { description: OK }
  /pets/{petId}:
    get:
      operationId: getPet
      parameters:
        - in: path
          name: petId
          required: true
          schema: { type: string }
      responses:
        '200': { description: OK }
```
You can export this YAML directly from Swagger or FastAPI projects.

How It Works (Logic Flow)
```
Jira (changes.json)
        â”‚
        â–¼
OpenAPI Spec (my_api.yaml)
        â”‚
        â–¼
RequirementAgent
        â”‚
        â”œâ”€â”€ Match Jira â†’ OpenAPI endpoints
        â”œâ”€â”€ Generate .feature files (gherkin)
        â”œâ”€â”€ Generate .py tests (pytest)
        â”œâ”€â”€ Apply schema + contract guardrails
        â–¼
Traceability Matrix (CSV + HTML)
        â–¼
Pytest Execution (--offline or --base-url)
```
ğŸ§® Usage

ğŸ§  Step 1 â€“ Generate tests
```
python -m t2t.cli generate --openapi data/openapi/my_api.yaml --jira data/jira/changes.json --out out
```
This will create:
```
out/features/*.feature

out/tests/*.py
```
ğŸ“Š Step 2 â€“ Build Traceability
```
python -m t2t.cli traceability --run-dir out --csv out/traceability.csv --html out/traceability.html

```
Open the HTML file to view the requirement-to-test coverage table.
ğŸ§ª Step 3 â€“ Run Tests
Offline Mode (no real API calls)
```
python -m pytest -q out/tests --offline
```
Real API Mode
```
python -m pytest -q out/tests --base-url https://api.example.com
```

You can use any live API, such as:

Your local FastAPI server (uvicorn main:app --port 8000)

Public demo APIs like https://petstore.swagger.io/v2

ğŸ§¾ Continuous Integration (CI)

GitHub Actions automatically runs this workflow (.github/workflows/tests.yml):
```
name: t2t-tests
on: [push, pull_request]

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Create venv & install deps
        run: |
          python -m venv .venv
          .venv/bin/python -m pip install --upgrade pip
          .venv/bin/pip install -r requirements.txt
          .venv/bin/pip install -e .
          .venv/bin/pip install pytest
      - name: Generate tests
        run: .venv/bin/python -m t2t.cli generate --openapi data/openapi/my_api.yaml --jira data/jira/changes.json --out out
      - name: Traceability
        run: .venv/bin/python -m t2t.cli traceability --run-dir out --csv out/traceability.csv --html out/traceability.html
      - name: Run pytest (offline)
        run: .venv/bin/python -m pytest -q out/tests --offline

```
This ensures your project is automatically validated every time you push.

ğŸ§° Example Output
```
out/
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ REQ-201.feature
â”‚   â””â”€â”€ REQ-202.feature
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_req_REQ_201.py
â”‚   â””â”€â”€ test_req_REQ_202.py
â”œâ”€â”€ traceability.csv
â””â”€â”€ traceability.html

```
And pytest console output:
```
...                                                                    [100%]
3 passed in 1.21s
```
ğŸ’¡ Key Advantages

ğŸ” End-to-end automation (Requirements â†’ Tests â†’ Results)

ğŸ“Š Live traceability reports

âš™ï¸ Contract-aware, schema-validated test generation

ğŸ§ª Runs offline or against real APIs

â˜ï¸ Integrated with GitHub CI/CD pipelines

ğŸ§± Tech Stack
```
Category	Tools
Language	Python 3.11
Test Framework	pytest
API Spec Format	OpenAPI 3.0
Automation	GitHub Actions
Validation	requests, pyyaml, jsonschema
Reports	CSV, HTML traceability
```
ğŸ“˜ Example Use Case

Jira ticket: â€œREQ-202 â€” Create a new petâ€

Jira entry in changes.json

Matching OpenAPI path /pets with POST

T2T generates:

REQ-202.feature

test_req_REQ_202_createPet.py

The test runs automatically against the API and reports âœ… or âŒ

Traceability matrix updates REQ-202 â†’ /pets â†’ test_req_REQ_202_createPet.py


ğŸ Summary

T2T bridges the gap between requirements engineering and automated testing by generating, validating, and running tests directly from your API contract and Jira inputs.

It provides:

âœ… Faster test creation

âœ… Guaranteed traceability

âœ… Continuous verification in CI

â€œIf your requirements are clear, your tests should be ready in seconds.â€ ğŸ’¡
